{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext lab_black"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following models will be created:\n",
    "* random forest\n",
    "* neural network\n",
    "* gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import dalex as dx\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"resources/data/housing_preproc.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop(columns=[\"median_house_value\"]), df[[\"median_house_value\"]]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time: 1h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestRegressor(criterion='absolute_error', max_depth=9,\n",
      "                      max_features='sqrt', min_samples_leaf=2,\n",
      "                      n_estimators=300)\n"
     ]
    }
   ],
   "source": [
    "# rf = RandomForestRegressor()\n",
    "# rf_tuned = RandomizedSearchCV(\n",
    "#     rf,\n",
    "#     {\n",
    "#         \"criterion\": [\"squared_error\", \"absolute_error\"],\n",
    "#         \"max_features\": [\"sqrt\", \"log2\"],\n",
    "#         \"min_samples_split\": [i for i in range(2, 10)],\n",
    "#         \"min_samples_leaf\": [i for i in range(1, 3)],\n",
    "#         \"max_depth\": [i for i in range(3, 10, 2)],\n",
    "#         \"n_estimators\": [i for i in range(100, 301, 100)],\n",
    "#     },\n",
    "#     n_iter=10,\n",
    "#     random_state=2137,\n",
    "# )\n",
    "\n",
    "# rf_tuned.fit(X_train, y_train)\n",
    "# print(rf_tuned.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"resources/models/random_forest.pkl\", \"wb\") as file:\n",
    "#     pkl.dump(file=file, obj=rf_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time: 5 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(hidden_layer_sizes=(10, 100, 20), random_state=2137)\n"
     ]
    }
   ],
   "source": [
    "# mlp = MLPRegressor(random_state=2137)\n",
    "\n",
    "# mlp_tuned = GridSearchCV(\n",
    "#     mlp, {\"hidden_layer_sizes\": [(10, 100, 20), (5, 50, 50, 10), (25, 100, 20)]}\n",
    "# )\n",
    "\n",
    "# mlp_tuned.fit(X_train, y_train)\n",
    "# print(mlp_tuned.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"resources/models/neural_network.pkl\", \"wb\") as file:\n",
    "#     pkl.dump(file=file, obj=mlp_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradiendt Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time: 0.5h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingRegressor(criterion='mse', max_features='auto')\n"
     ]
    }
   ],
   "source": [
    "# gb = GradientBoostingRegressor()\n",
    "\n",
    "# gb_tuned = RandomizedSearchCV(\n",
    "#     gb,\n",
    "#     {\n",
    "#         \"loss\": [\"squared_error\", \"absolute_error\", \"huber\", \"quantile\"],\n",
    "#         \"criterion\": [\"friedman_mse\", \"squared_error\", \"mse\"],\n",
    "#         \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "#     },\n",
    "#     random_state=2137,\n",
    "#     n_iter=15,\n",
    "# )\n",
    "\n",
    "# gb_tuned.fit(X_train, y_train)\n",
    "# print(gb_tuned.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"resources/models/gradient_boosting.pkl\", \"wb\") as file:\n",
    "#     pkl.dump(file=file, obj=gb_tuned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time: 1min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor(criterion='absolute_error', max_features='auto',\n",
      "                      min_samples_split=8)\n"
     ]
    }
   ],
   "source": [
    "# dt = DecisionTreeRegressor()\n",
    "\n",
    "# dt_tunned = RandomizedSearchCV(\n",
    "#     dt,\n",
    "#     {\n",
    "#         \"criterion\": [\"squared_error\", \"friedman_mse\", \"absolute_error\", \"poisson\"],\n",
    "#         \"max_features\": [\"auto\", \"sqrt\", \"log2\"],\n",
    "#         \"min_samples_split\": [i for i in range(2, 10, 2)],\n",
    "#     },\n",
    "# )\n",
    "\n",
    "# dt_tunned.fit(X_train, y_train)\n",
    "# print(dt_tunned.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"resources/models/decision_tree.pkl\", \"wb\") as file:\n",
    "#     pkl.dump(file=file, obj=dt_tunned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models evaluaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"resources/models/random_forest.pkl\", \"rb\") as file:\n",
    "    rf = pkl.load(file)\n",
    "\n",
    "with open(\"resources/models/neural_network.pkl\", \"rb\") as file:\n",
    "    mlp = pkl.load(file)\n",
    "\n",
    "with open(\"resources/models/gradient_boosting.pkl\", \"rb\") as file:\n",
    "    gb = pkl.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 20640 rows 13 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 20640 values\n",
      "  -> model_class       : sklearn.model_selection._search.RandomizedSearchCV (default)\n",
      "  -> label             : random forest\n",
      "  -> predict function  : <function yhat_default at 0x7fdcfd5d6d30> will be used (default)\n",
      "  -> predict function  : Accepts pandas.DataFrame and numpy.ndarray.\n",
      "  -> predicted values  : min = -1.27, mean = -0.0772, max = 2.5\n",
      "  -> model type        : regression will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -2.22, mean = 0.0772, max = 3.35\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 20640 rows 13 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 20640 values\n",
      "  -> model_class       : sklearn.model_selection._search.GridSearchCV (default)\n",
      "  -> label             : neural network\n",
      "  -> predict function  : <function yhat_default at 0x7fdcfd5d6d30> will be used (default)\n",
      "  -> predict function  : Accepts pandas.DataFrame and numpy.ndarray.\n",
      "  -> predicted values  : min = -1.63, mean = -0.0198, max = 3.15\n",
      "  -> model type        : regression will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -3.0, mean = 0.0198, max = 3.79\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n",
      "Preparation of a new explainer is initiated\n",
      "\n",
      "  -> data              : 20640 rows 13 cols\n",
      "  -> target variable   : Parameter 'y' was a pandas.DataFrame. Converted to a numpy.ndarray.\n",
      "  -> target variable   : 20640 values\n",
      "  -> model_class       : sklearn.model_selection._search.RandomizedSearchCV (default)\n",
      "  -> label             : gradient boosting\n",
      "  -> predict function  : <function yhat_default at 0x7fdcfd5d6d30> will be used (default)\n",
      "  -> predict function  : Accepts pandas.DataFrame and numpy.ndarray.\n",
      "  -> predicted values  : min = -1.49, mean = -0.000168, max = 3.02\n",
      "  -> model type        : regression will be used (default)\n",
      "  -> residual function : difference between y and yhat (default)\n",
      "  -> residuals         : min = -2.89, mean = 0.000168, max = 3.41\n",
      "  -> model_info        : package sklearn\n",
      "\n",
      "A new explainer has been created!\n"
     ]
    }
   ],
   "source": [
    "rf_exp = dx.Explainer(rf, X, y, label=\"random forest\")\n",
    "mlp_exp = dx.Explainer(mlp, X, y, label=\"neural network\")\n",
    "gb_exp = dx.Explainer(gb, X, y, label=\"gradient boosting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_performance = rf_exp.model_performance(model_type=\"regression\")\n",
    "mlp_performance = mlp_exp.model_performance(model_type=\"regression\")\n",
    "gb_performance = gb_exp.model_performance(model_type=\"regression\")\n",
    "\n",
    "performance = pd.concat(\n",
    "    [rf_performance.result, mlp_performance.result, gb_performance.result]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae</th>\n",
       "      <th>mad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neural network</th>\n",
       "      <td>0.184930</td>\n",
       "      <td>0.430035</td>\n",
       "      <td>0.815070</td>\n",
       "      <td>0.287642</td>\n",
       "      <td>0.187932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gradient boosting</th>\n",
       "      <td>0.216974</td>\n",
       "      <td>0.465804</td>\n",
       "      <td>0.783026</td>\n",
       "      <td>0.324272</td>\n",
       "      <td>0.230234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random forest</th>\n",
       "      <td>0.231571</td>\n",
       "      <td>0.481218</td>\n",
       "      <td>0.768429</td>\n",
       "      <td>0.320396</td>\n",
       "      <td>0.211325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        mse      rmse        r2       mae       mad\n",
       "neural network     0.184930  0.430035  0.815070  0.287642  0.187932\n",
       "gradient boosting  0.216974  0.465804  0.783026  0.324272  0.230234\n",
       "random forest      0.231571  0.481218  0.768429  0.320396  0.211325"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance.sort_values(by=\"r2\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network perform best on all metrics and will be used as primary models throughout rest of the project."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ba48d6b592de4413469d41fbbc1baaa0eb6042c5d519f9b4ec7f4515281862f8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.2 ('WB2022')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
